{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import binascii\n",
    "from bisect import bisect_right\n",
    "from heapq import heappop, heappush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simliarity Hashing adapted from:\n",
    "# http://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/\n",
    "\n",
    "#=========================================================#\n",
    "#                  Initial Parameters                     #\n",
    "#=========================================================#\n",
    "\n",
    "# Shingle Size determines the length of identical consecutive characters two documents must have\n",
    "# in order to be considered identical. This generally works well between 30-50.\n",
    "\n",
    "# Too small sized shingles can result in false positive matching hashes based on short strings\n",
    "# like dates and email addresses.\n",
    "# if shingleSize = 18\n",
    "# \"The quick brown fox jumps over the lazy dog on 31 August 2018\"\n",
    "# \"[SPAM] and [ADV] should automatically be flagged as false positive on 31 August 2018\"\n",
    "# will produce a matching MinHash due the the matching shingle of \"31 August 2018\"\n",
    "#\n",
    "# Too long sized shigles means short documents that are similar will not be matched due to not\n",
    "# having a common shingle of shingle size.\n",
    "# if shingleSize=10\n",
    "# \"123456789RYAN123456789\"\n",
    "# \"123456789JACK123456789\"\n",
    "# will not match, since there are no 10 consecutive charaters that produce a match, despite the\n",
    "# similarity\n",
    "#\n",
    "# In general, this method of similarity clustering is good at picking out emails that follow a\n",
    "# uniform formatting, especially identifying reused phrases and links. When viewing all emails,\n",
    "# many false positive groupings are identified, especially due to the standard \"If you are not\n",
    "# the intended recepient...\", and uniform organizational message signatures. However, when\n",
    "# filtered to view only TRUE POSITIVE emails, this is beneficial as it is able to detect not only near-duplicates,\n",
    "# has a side effect of grouping non-similiar emails from the same external organization and\n",
    "# non-similiar emails that include identical links/phone numbers, indicating similarity in source.\n",
    "\n",
    "shingleSize = 30\n",
    "\n",
    "# Maximum possible hashedMessageShingle.\n",
    "# maxShingleID = 2**32-1 = 4294967295\n",
    "# https://en.wikipedia.org/wiki/4,294,967,295\n",
    "\n",
    "# The next largest prime number above 'maxShingleID'.\n",
    "nextPrime = 4294967311\n",
    "\n",
    "# coeffA and coeffB are random coefficients, used as random seeds for the hashing.\n",
    "coeffA = 740052807\n",
    "coeffB = 954911726\n",
    "\n",
    "#=========================================================#\n",
    "#                  Importing Data                         #\n",
    "#=========================================================#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv(\"emails.csv\", encoding = \"Latin-1\", usecols=[\"text\"])\n",
    "# print df_raw.head()\n",
    "\n",
    "#=========================================================#\n",
    "#               Writing .apply function                   #\n",
    "#=========================================================#\n",
    "\n",
    "def get_min_hash(row):\n",
    "    \n",
    "    # Extracting the document to be hashed. In this case we want Sender + Subject + Message Body\n",
    "    messageBody = row[\"text\"]\n",
    "    abdc = messageBody.encode(\"utf8\",errors=\"ignore\")\n",
    "    \n",
    "    # rawHash represents the method of identical grouping\n",
    "    rawHash = binascii.crc32(abdc)& 0xffffffff\n",
    "    \n",
    "    # For Each Doc    : \"tech.gov.sg\"\n",
    "    # Step 1 Shingle  : set([\"tech\",\"ech.\",\"ch.g\",\"h.go\",\".gov\",\"gov.\",\"ov.s\",\"v.sg\"])\n",
    "    # Step 2 Checksum : [2260480018L, 383729972L, 2529353918L, 448064179L, 1999796693L, 1636650756L, 3497395457L, 2315752824L]\n",
    "    # Step 3 Hash     : [2813133948L, 1283942591L, 3815850831L, 2685560488L, 2528867967L, 986435944L, 310603638L, 1820640600L]\n",
    "    # Step 4 Minhash  : min(Hash) = 310603638L\n",
    "    \n",
    "    # Shingling Documents\n",
    "    messageShingles = set([messageBody[max(0, i - shingleSize):i] for i in range(shingleSize, len(messageBody) + 1)])\n",
    "    minHashCode = nextPrime + 1\n",
    "    minHashShingle = \"\"\n",
    "    for shingle in messageShingles:\n",
    "        shingle = shingle.encode(\"utf8\",errors=\"ignore\")\n",
    "        # Checksum\n",
    "        shingleID = (binascii.crc32(shingle)& 0xffffffff)\n",
    "        # Hash\n",
    "        hashCode = (coeffA * shingleID + coeffB) % nextPrime\n",
    "        if hashCode < minHashCode:\n",
    "            # MinHash\n",
    "            minHashCode = hashCode\n",
    "            # minHashShingle helps to identify which shingle the documents have in common\n",
    "            minHashShingle = shingle\n",
    "    minHashShingle = minHashShingle.replace('\\n','').replace('\\r','')\n",
    "    return minHashCode,rawHash,minHashShingle\n",
    "\n",
    "df_raw[[\"Minhash\",\"rawHash\",\"minHashShingle\"]] = df_raw.apply( lambda row: pd.Series(get_min_hash(row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw.sort_values(\"Minhash\").to_csv(\"emails_minHashed.csv\", encoding=\"utf-8\", sep=\",\",line_terminator=\"\\n\", mode='wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the CSV in EXCEL:\n",
    "\n",
    "# Identifying Documents with similarity matches\n",
    "# 1. Select cell H2, CTRL+SHIFT+DOWN to select entire row H\n",
    "# 2. Conditional formatting > Create a new rule\n",
    "# 3. Select a Rule Type: Use a formula to determine which cells to format\n",
    "# 4. Format values where this formula is true: \"=COUNTIF((H:H),H2)>1\"\n",
    "# 5. Format... : set desired format\n",
    "\n",
    "# Identifying Documents with identical matches\n",
    "# 6. Select cell I2, CTRL+SHIFT+DOWN to select entire row I\n",
    "# 7. Conditional formatting > Create a new rule\n",
    "# 8. Select a Rule Type: Use a formula to determine which cells to format\n",
    "# 9. Format values where this formula is true: \"=COUNTIF((I:I),I2)>1\"\n",
    "# 10. Format... : set desired format\n",
    "\n",
    "# Sorting\n",
    "# 11. Sort cells by value in column H to group similar emails into rows\n",
    "# 12. Sort cells by value in column I to group identical emails into rows\n",
    "# 13. CTRL+A to select all rows and adjust row height"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
